{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.17 join\n",
    "\n",
    "두 RDD에서 서로 같은 키를 가지고 있는 요소를 모아 그룹을 형성. 이 결과로 구성된 새로운 RDD를 생성.\n",
    "\n",
    "Tuple(키, Tuple(첫번째 RDD의 요소, 두번째 RDD의 요소)) 형태로 구성.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\", \"d\", \"e\")).map((_, 1))\n",
    "    val rdd2 = sc.parallelize(List(\"b\", \"c\")).map((_, 2))\n",
    "    val result = rdd1.join(rdd2)\n",
    "    println(result.collect.mkString(\"\\n\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<code>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data1 = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", 1), new Tuple2(\"c\", 1), new Tuple2(\"d\", 1), new Tuple2(\"e\", 1));\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data2 = Arrays.asList(new Tuple2(\"b\", 2), new Tuple2(\"c\", 2));\n",
    "    \n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd1 = sc.parallelizePairs(data1);\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd2 = sc.parallelizePairs(data2);\n",
    "    \n",
    "    JavaPairRDD&lt;String, Tuple2&lt;Integer, Integer&gt;&gt; result = rdd1.&lt;Integer&gt;join(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', (1, 2)), ('b', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"]).map(lambda v: (v, 1), 1)\n",
    "rdd2 = sc.parallelize([\"b\", \"c\"]).map(lambda v: (v, 2), 1)\n",
    "result = rdd1.join(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', (2, 1)), ('b', (2, 1))]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"]).map(lambda v: (v, 1))\n",
    "rdd2 = sc.parallelize([\"b\", \"c\"]).map(lambda v: (v, 2))\n",
    "result = rdd2.join(rdd1)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.18 leftOuterJoin, rightOuterJoin\n",
    "\n",
    "왼쪽 외부 조인과 오른쪽 외부 조인을 수행하고, 그 결과로 구성된 새로운 RDD를 돌려줌.\n",
    "\n",
    "catesian() 메서드의 실행 결과에는 나타나지 않았던 요소들이 포함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\")).map((_, 1))\n",
    "    val rdd2 = sc.parallelize(List(\"b\", \"c\")).map((_, 2))\n",
    "    val result1 = rdd1.leftOuterJoin(rdd2)\n",
    "    val result2 = rdd1.rightOuterJoin(rdd2)\n",
    "    println(\"Left: \" + result1.collect.mkString(\"\\t\"))\n",
    "    println(\"Right: \" + result2.collect.mkString(\"\\t\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data1 = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", \"1\"), new Tuple2(\"c\", \"1\"));\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data2 = Arrays.asList(new Tuple2(\"b\", 2), new Tuple2(\"c\", \"2\"));\n",
    "\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd1 = sc.parallelizePairs(data1);\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd2 = sc.parallelizePairs(data2);\n",
    "\n",
    "    JavaPairRDD&lt;String, Tuple2&lt;Integer, Optional&lt;Integer&gt;&gt;&gt; result1 = rdd1.&lt;Integer&gt;leftOuterJoin(rdd2);\n",
    "    JavaPairRDD&lt;String, Tuple2&lt;Optional&lt;Integer&gt;, Integer&gt;&gt; result2 = rdd1.&lt;Integer&gt;rightOuterJoin(rdd2);\n",
    "    System.out.println(\"Left: \" + result1.collect());\n",
    "    System.out.println(\"Right: \" + result2.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: [('a', (1, None)), ('c', (1, 2)), ('b', (1, 2))]\n",
      "Right: [('c', (1, 2)), ('b', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\"]).map(lambda v: (v, 1))\n",
    "rdd2 = sc.parallelize([\"b\", \"c\"]).map(lambda v: (v, 2))\n",
    "result1 = rdd1.leftOuterJoin(rdd2)\n",
    "result2 = rdd1.rightOuterJoin(rdd2)\n",
    "print(\"Left: %s\" % result1.collect())\n",
    "print(\"Right: %s\" % result2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.19 subtractByKey\n",
    "\n",
    "rdd1.subtractByKey(rdd2)는 rdd1의 요소 중에서 rdd2에 같은 키가 존재하는 요소를 제외한 나머지로 구성된 새로운 RDD를 돌려줌.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\")).map((_, 1))\n",
    "    val rdd2 = sc.parallelize(List(\"b\")).map((_, 2))\n",
    "    val result = rdd1.subtractByKey(rdd2)\n",
    "    println(result.collect.mkString(\"\\n\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data1 = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", 1));\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data2 = Arrays.asList(new Tuple2(\"b\", 2));\n",
    "    \n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd1 = sc.parallelizePairs(data1);\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd2 = sc.parallelizePairs(data2);\n",
    "    \n",
    "    JavaPairRDD&lt;String, Integer&gt; result = rdd1.subtractByKey(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\"]).map(lambda v: (v, 1))\n",
    "rdd2 = sc.parallelize([\"b\"]).map(lambda v: (v, 2))\n",
    "result = rdd1.subtractByKey(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.20 reduceByKey\n",
    "\n",
    "같은 키를 가진 값들을 하나로 병합해 키-값 쌍으로 구성된 새로운 RDD를 생성.\n",
    "\n",
    "두 개의 값을 하나로 합치는 함수를 인자로 전달 받으며 이 함수는 결합법칙과 교환법칙이 성립해야 함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"a\", \"b\", \"b\")).map((_, 1))\n",
    "    val result = rdd.reduceByKey(_ + _)\n",
    "    println(result.collect.mkString(\",\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", 1), new Tuple2(\"b\", 1));\n",
    "\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd = sc.parallelizePairs(data);\n",
    "\n",
    "    // Java7\n",
    "    JavaPairRDD&lt;String, Integer&gt; result = rdd.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {\n",
    "      @Override\n",
    "      public Integer call(Integer v1, Integer v2) throws Exception {\n",
    "        return v1 + v2;\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaPairRDD&lt;String, Integer&gt; result2 = rdd.reduceByKey((Integer v1, Integer v2) -&gt; v1 + v2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 2), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"b\"]).map(lambda v: (v, 1))\n",
    "result = rdd.reduceByKey(lambda v1, v2: v1 + v2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RDD의 트랜스포메이션 메서드에는 데이터 처리 과정에서 사용할 파티셔너와 파티션 개수를 지정할 수 있는 옵션 존재."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.21 foldByKey\n",
    "\n",
    "reduceByKey와 유사하게 같은 키를 가진 값들을 하나로 병합해 키-값 쌍으로 구성된 새로운 RDD를 생성.\n",
    "\n",
    "초기값을 메서드의 인자로 전달해서 병합 시 사용가능.\n",
    "\n",
    "각 단위 병합 단계에서 결과에 영향이 없는 값을 초기값으로 사용하므로 이 함수는 교환법칙만 만족하면 사용가능.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"a\", \"b\", \"b\")).map((_, 1))\n",
    "    val result = rdd.foldByKey(0)(_ + _)\n",
    "    println(result.collect.mkString(\",\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", 1), new Tuple2(\"b\", 1));\n",
    "\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd = sc.parallelizePairs(data);\n",
    "\n",
    "    // Java7\n",
    "    JavaPairRDD&lt;String, Integer&gt; result = rdd.foldByKey(0, new Function2&lt;Integer, Integer, Integer&gt;() {\n",
    "      @Override\n",
    "      public Integer call(Integer v1, Integer v2) throws Exception {\n",
    "        return v1 + v2;\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaPairRDD&lt;String, Integer&gt; result2 = rdd.foldByKey(0, (Integer v1, Integer v2) -&gt; v1 + v2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 2), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"b\"]).map(lambda v: (v, 1))\n",
    "result = rdd.foldByKey(0, lambda v1, v2: v1 + v2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.22 combineByKey\n",
    "\n",
    "같은 키를 가진 값들을 하나로 병합하는 기능을 수행. 병합을 수행하는 과정에서 값의 타입이 바뀔 수 있음.\n",
    "\n",
    "기존 병합 함수의 스칼라 API\n",
    "<pre>\n",
    "def reduceByKey(func: (V, V) => V): RDD[(K, V)]\n",
    "def foldByKey(zerovalue: V)(func: (V, V) => V): RDD[(K, V)]\n",
    "</pre>\n",
    "\n",
    "combineByKey 스칼라 API, C는 클래스\n",
    "<pre>\n",
    "def combineByKey[C](createCombiner: (V) => C, mergeValue: (C, V), mergeCombiners: (C, C) => C): RDD[(K, C)]\n",
    "</pre>\n",
    "\n",
    "인자로 지정된 3개의 함수 의미\n",
    "* createCombiner() : 값을 병합하기 위한 콤바이너를 생성. 두 개의 값을 하나로 병합하는 객체. 각 키별로 생성됨.\n",
    "* mergeValue() : 키에 대한 콤바이너가 이미 존재한다면 이 함수를 이용해 값을 기존 콤바이너에 병합.\n",
    "* createCombiner(), mergeValue()는 파티션 단위로 수행\n",
    "* mergeCombiners() : 병합이 끝난 콤바이너끼리 다시 병합을 수행해 최종 콤바이너를 생성. 최종 결과를 생성함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "case class Record(var amount: Long, var number: Long = 1) {\n",
    "    def map(v: Long) = Record(v)\n",
    "    def add(amount: Long): Record = {\n",
    "        add(map(amount))\n",
    "     }\n",
    "    def add(other: Record): Record = {\n",
    "        this.number += other.number\n",
    "        this.amount += other.amount\n",
    "        this\n",
    "    }\n",
    "    override def toString: String = s\"avg:${amount / number}\"\n",
    "}\n",
    "// combineByKey()를 이용한 평균값 계산\n",
    "val data = Seq((\"Math\", 100L), (\"Eng\", 80L), (\"Math\", 50L), (\"Eng\", 70L), (\"Eng\", 90L))\n",
    "val rdd = sc.parallelize(data)\n",
    "val createCombiner = (v: Long) => Record(v)\n",
    "val mergeValue = (c: Record, v: Long) => c.add(v)\n",
    "val mergeCombiners = (c1: Record, c2: Record) => c1.add(c2)\n",
    "val result = rdd.combineByKey(createCombiner, mergeValue, mergeCombiners)\n",
    "println(result.collect.mkString(\",\\t\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Long&gt;&gt; data = Arrays.asList(new Tuple2(\"Math\", 100L), new Tuple2(\"Eng\", 80L), new Tuple2(\"Math\", 50L), new Tuple2(\"Eng\", 70L), new Tuple2(\"Eng\", 90L));\n",
    "\n",
    "    JavaPairRDD&lt;String, Long&gt; rdd = sc.parallelizePairs(data);\n",
    "\n",
    "    // Java7\n",
    "    Function&lt;Long, Record&gt; createCombiner = new Function&lt;Long, Record&gt;() {\n",
    "      @Override\n",
    "      public Record call(Long v) throws Exception {\n",
    "        return new Record(v);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    Function2&lt;Record, Long, Record&gt; mergeValue = new Function2&lt;Record, Long, Record&gt;() {\n",
    "      @Override\n",
    "      public Record call(Record record, Long v) throws Exception {\n",
    "        return record.add(v);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    Function2&lt;Record, Record, Record&gt; mergeCombiners = new Function2&lt;Record, Record, Record&gt;() {\n",
    "      @Override\n",
    "      public Record call(Record r1, Record r2) throws Exception {\n",
    "        return r1.add(r2);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    JavaPairRDD&lt;String, Record&gt; result = rdd.combineByKey(createCombiner, mergeValue, mergeCombiners);\n",
    "\n",
    "    // Java8\n",
    "    JavaPairRDD&lt;String, Record&gt; result2 = rdd.combineByKey((Long v) -&gt; new Record(v), (Record record, Long v) -&gt; record.add(v), (Record r1, Record r2) -&gt; r1.add(r2));\n",
    "\n",
    "    System.out.println(result.collect());\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 파이썬 - 다음 소스는 jupyter notebook에서 바로 실행 불가.\n",
    "# https://stackoverflow.com/questions/28569374/spark-returning-pickle-error-cannot-lookup-attribute\n",
    "record_py = \"\"\"class Record:\n",
    "    def __init__(self, amount, number=1):\n",
    "        self.amount = amount\n",
    "        self.number = number\n",
    "        \n",
    "    def addAmt(self, amount):\n",
    "        return Record(self.amount + amount, self.number + 1)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        amount = self.amount + other.amount\n",
    "        number = self.number + other.number \n",
    "        return Record(amount, number)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"avg:\" + str(self.amount / self.number)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Record(%r, %r)' % (self.amount, self.number)\n",
    "\"\"\"\n",
    "\n",
    "src = \"\"\"import pyspark\n",
    "from record import *\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "def createCombiner(v):\n",
    "    return Record(v)\n",
    "\n",
    "def mergeValue(c, v):\n",
    "    return c.addAmt(v)\n",
    "\n",
    "def mergeCombiners(c1, c2):\n",
    "    return c1 + c2\n",
    "\n",
    "rdd = sc.parallelize([(\"Math\", 100), (\"Eng\", 80), (\"Math\", 50), (\"Eng\", 70), (\"Eng\", 90)])\n",
    "result = rdd.combineByKey(lambda v: createCombiner(v), lambda c, v: mergeValue(c, v),\n",
    "                                  lambda c1, c2: mergeCombiners(c1, c2))\n",
    "\n",
    "print('Math', result.collectAsMap()['Math'], 'Eng', result.collectAsMap()['Eng'])\n",
    "\"\"\"\n",
    "\n",
    "with open('record.py', 'w') as f:\n",
    "    f.write(record_py)\n",
    "with open('job.py', 'w') as f:\n",
    "    f.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math avg:75.0 Eng avg:80.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "$SPARK_HOME/bin/spark-submit --py-files record.py job.py 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.remove('record.py')\n",
    "os.remove('job.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.23 aggregateByKey\n",
    "\n",
    "combineByKey()의 특수한 경우로 초기값을 생성하는 부분을 제외하면 동일한 동작을 수행.\n",
    "\n",
    "def aggregateByKey[U](zeroValue: U)(seqOp: (U, V) => U, combOp: (U, U) => U): RDD[(K, U)]\n",
    "\n",
    "seqOp은 mergeValue(), combOp은 mergeCombiner()와 서로 같은 역할을 하는 함수.\n",
    "\n",
    "병합에 필요한 초기값을 알 기 위해 zeroValue라는 \"값\"을 사용함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val data = Seq((\"Math\", 100L), (\"Eng\", 80L), (\"Math\", 50L), (\"Eng\", 70L), (\"Eng\", 90L))\n",
    "    val rdd = sc.parallelize(data)\n",
    "    val zero = Record(0, 0)\n",
    "    val mergeValue = (c: Record, v: Long) => c.add(v)\n",
    "    val mergeCombiners = (c1: Record, c2: Record) => c1.add(c2)\n",
    "    val result = rdd.aggregateByKey(zero)(mergeValue, mergeCombiners)\n",
    "    println(result.collect.mkString(\",\\t\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "List&lt;Tuple2&lt;String, Long&gt;&gt; data = Arrays.asList(new Tuple2(\"Math\", 100L), new Tuple2(\"Eng\", 80L), new Tuple2(\"Math\", 50L), new Tuple2(\"Eng\", 70L), new Tuple2(\"Eng\", 90L));\n",
    "\n",
    "    JavaPairRDD&lt;String, Long&gt; rdd = sc.parallelizePairs(data);\n",
    "\n",
    "    // Java7\n",
    "    Record zero = new Record(0, 0);\n",
    "\n",
    "    Function2&lt;Record, Long, Record&gt; mergeValue = new Function2&lt;Record, Long, Record&gt;() {\n",
    "      @Override\n",
    "      public Record call(Record record, Long v) throws Exception {\n",
    "        return record.add(v);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    Function2&lt;Record, Record, Record&gt; mergeCombiners = new Function2&lt;Record, Record, Record&gt;() {\n",
    "      @Override\n",
    "      public Record call(Record r1, Record r2) throws Exception {\n",
    "        return r1.add(r2);\n",
    "      }\n",
    "    };\n",
    "\n",
    "    JavaPairRDD&lt;String, Record&gt; result = rdd.aggregateByKey(zero, mergeValue, mergeCombiners);\n",
    "\n",
    "    // Java8\n",
    "    JavaPairRDD&lt;String, Record&gt; result2 = rdd.aggregateByKey(zero, (Record record, Long v) -&gt; record.add(v), (Record r1, Record r2) -&gt; r1.add(r2));\n",
    "\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파이썬 - 다음 소스는 jupyter notebook에서 바로 실행 불가.\n",
    "src = \"\"\"import pyspark\n",
    "from record import *\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "def mergeValue(c, v):\n",
    "    return c.addAmt(v)\n",
    "\n",
    "def mergeCombiners(c1, c2):\n",
    "    return c1 + c2\n",
    "\n",
    "rdd = sc.parallelize([(\"Math\", 100), (\"Eng\", 80), (\"Math\", 50), (\"Eng\", 70), (\"Eng\", 90)])\n",
    "result = rdd.aggregateByKey(Record(0, 0), lambda c, v: mergeValue(c, v), lambda c1, c2: mergeCombiners(c1, c2))\n",
    "print('Math', result.collectAsMap()['Math'], 'Eng', result.collectAsMap()['Eng'])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('job.py', 'w') as f:\n",
    "    f.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math avg:75.0 Eng avg:80.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "$SPARK_HOME/bin/spark-submit --py-files record.py job.py 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove('record.py')\n",
    "os.remove('job.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [pipe 및 파티션 관련 연산]\n",
    "\n",
    "#### 2.1.5.24 pipe\n",
    "\n",
    "pipe를 이용하면 데이터를 처리하는 과정에서 외부 프로세스 활용 가능.\n",
    "\n",
    "cut 유틸리티를 이용해 문자열 분리 후 첫 번째와 세 번째 숫자를 뽑아내는 예제\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"1,2,3\", \"4,5,6\", \"7,8,9\"))\n",
    "    val result = rdd.pipe(\"cut -f 1,3 -d ,\")\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd = sc.parallelize(Arrays.asList(\"1,2,3\", \"4,5,6\", \"7,8,9\"));\n",
    "    JavaRDD&lt;String&gt; result = rdd.pipe(\"cut -f 1,3 -d ,\");\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,3', '4,6', '7,9']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([\"1,2,3\", \"4,5,6\", \"7,8,9\"])\n",
    "result = rdd.pipe(\"cut -f 1,3 -d ,\")\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.25 coelesce와 repartition\n",
    "\n",
    "repartition() : 파티션 수를 늘리거나 줄이는 것 모두 가능. 셔플을 기반으로 동작. 파티션을 늘릴 경우 주로 사용.\n",
    "    \n",
    "coalesce() : 줄이는 것만 가능. 셔플옵션 없으면 셔플 안함. 파티션을 줄일 경우 주로 사용.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(1 to 1000000, 10)\n",
    "    val rdd2 = rdd1.coalesce(5)\n",
    "    val rdd3 = rdd2.repartition(10);\n",
    "    println(s\"partition size: ${rdd1.getNumPartitions}\")\n",
    "    println(s\"partition size: ${rdd2.getNumPartitions}\")\n",
    "    println(s\"partition size: ${rdd3.getNumPartitions}\")\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 0), 10);\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = rdd1.coalesce(5);\n",
    "    JavaRDD&lt;Integer&gt; rdd3 = rdd2.coalesce(10);\n",
    "    System.out.println(\"partition size:\" + rdd1.getNumPartitions());\n",
    "    System.out.println(\"partition size:\" + rdd2.getNumPartitions());\n",
    "    System.out.println(\"partition size:\" + rdd3.getNumPartitions());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition size: 10\n",
      "partition size: 5\n",
      "partition size: 10\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize(list(range(1, 11)), 10)\n",
    "rdd2 = rdd1.coalesce(5)\n",
    "rdd3 = rdd2.repartition(10)\n",
    "print(\"partition size: %d\" % rdd1.getNumPartitions())\n",
    "print(\"partition size: %d\" % rdd2.getNumPartitions())\n",
    "print(\"partition size: %d\" % rdd3.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.26 repartitionAndSortWithinPartitions\n",
    "\n",
    "RDD를 구성하는 모든 데이터를 특정 기준에 따라 여러 개의 파티션으로 분리하고 각 파티션 단위로 정렬을 수행한 뒤 이 결과로 새로운 RDD를 생성해 주는 메서드.\n",
    "\n",
    "데이터가 키와 값 쌍으로 구성돼 있어야 함.\n",
    "\n",
    "파티셔너 : 각 데이터의 키 값을 이용해 데이터가 속할 파티션을 결정. 이 때 키 값을 이용한 정렬도 함께 수행.\n",
    "\n",
    "10개의 무작위 숫자를 3개의 파티션으로 분리해 보는 예제\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val r = scala.util.Random\n",
    "    val data = for (i &lt;- 1 to 10) yield (r.nextInt(100), \"-\")\n",
    "    val rdd1 = sc.parallelize(data)\n",
    "    val rdd2 = rdd1.repartitionAndSortWithinPartitions(new HashPartitioner(3))\n",
    "    rdd2.foreachPartition(it =&gt; {\n",
    "      println(\"==========\");\n",
    "      it.foreach(v => println(v))\n",
    "    })\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Integer&gt; data = fillToNRandom(10);\n",
    "    JavaPairRDD&lt;Integer, String&gt; rdd1 = sc.parallelize(data).mapToPair((Integer v) -&gt; new Tuple2(v, \"-\"));\n",
    "    JavaPairRDD&lt;Integer, String&gt; rdd2 = rdd1.repartitionAndSortWithinPartitions(new HashPartitioner(3));\n",
    "\n",
    "    rdd2.foreachPartition(new VoidFunction&lt;Iterator&lt;Tuple2&lt;Integer, String&gt;&gt;&gt;() {\n",
    "      @Override\n",
    "      public void call(Iterator&lt;Tuple2&lt;Integer, String&gt;&gt; it) throws Exception {        System.out.println(\"==========\");\n",
    "        while (it.hasNext()) {\n",
    "          System.out.println(it.next());\n",
    "        }\n",
    "      }\n",
    "    });\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, '-'),\n",
       " (42, '-'),\n",
       " (96, '-'),\n",
       " (43, '-'),\n",
       " (64, '-'),\n",
       " (91, '-'),\n",
       " (97, '-'),\n",
       " (8, '-'),\n",
       " (32, '-'),\n",
       " (44, '-')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이썬\n",
    "import random\n",
    "data = [random.randrange(1, 100) for i in range(0, 10)]\n",
    "rdd1 = sc.parallelize(data).map(lambda v: (v, \"-\"))\n",
    "rdd2 = rdd1.repartitionAndSortWithinPartitions(3, lambda x: x)\n",
    "# 결과 검증\n",
    "# rdd2.foreachPartition(lambda values: print(list(values)))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foreachPartition() 메서드는 RDD의 파티션 단위로 특정 함수를 실행해 주는 메서드.\n",
    "\n",
    "결과 : 각 기 값에 따라 파티션이 분리되고 동시에 키 값에 따라 정렬."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.1.5.27 partitionBy\n",
    "\n",
    "RDD 구성요소가 키와 값의 쌍으로 구성된 경우 사용할 수 있는 메서드.\n",
    "\n",
    "Partitioner 클래스의 인스턴스를 인자로 전달.\n",
    "\n",
    "HashPartitioner, RangePartitioner 두 종류 존재. 파티션 생성 기준을 변경하고 싶으면 Partitioner 클래스를 상속.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"apple\", \"mouse\", \"monitor\"), 5).map { a => (a, a.length) }\n",
    "    val rdd2 = rdd1.partitionBy(new HashPartitioner(3))\n",
    "    println(s\"rdd1:${rdd1.getNumPartitions}, rdd2:${rdd2.getNumPartitions}\")\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data = Arrays.asList(new Tuple2(\"apple\", 1), new Tuple2(\"mouse\", 1), new Tuple2(\"monitor\", 1));\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd1 = sc.parallelizePairs(data, 5);\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd2 = rdd1.partitionBy(new HashPartitioner(3));\n",
    "    System.out.println(\"rdd1:\" + rdd1.getNumPartitions() + \", rdd2:\" + rdd2.getNumPartitions());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1: 5, rdd2: 3\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([(\"apple\", 1), (\"mouse\", 1), (\"monitor\", 1)], 5)\n",
    "rdd2 = rdd1.partitionBy(3)\n",
    "print(\"rdd1: %d, rdd2: %d\" % (rdd1.getNumPartitions(), rdd2.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필터와 정렬 연산\n",
    "\n",
    "#### 2.1.5.28 filter\n",
    "\n",
    "RDD의 원하는 요소만 남기고 원하지 않는 요소를 걸러내는 메서드.\n",
    "\n",
    "참 거짓으로 가려내는 함수를 RDD의 각 요소에 적용해 결과가 참인 것만 남김.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 5)\n",
    "    val result = rdd.filter(_ > 2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5));\n",
    "    JavaRDD&lt;Integer&gt; result = rdd.filter(new Function&lt;Integer, Boolean&gt;() {\n",
    "      @Override\n",
    "      public Boolean call(Integer v1) throws Exception {\n",
    "        return v1 &gt; 2;\n",
    "      }\n",
    "    });\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(1, 5+1))\n",
    "rdd2 = rdd1.filter(lambda i: i > 2)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.29 sortByKey\n",
    "\n",
    "sortByKey()는 키 값을 기준으로 요소를 정렬하는 연산.\n",
    "\n",
    "키 값을 기준으로 정렬하기 때문에 모든 요소가 키와 값 형태도 구성돼 있어야 함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"q\", \"z\", \"a\"))\n",
    "    val result = rdd.map((_, 1)).sortByKey()\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;&gt; data = Arrays.asList(new Tuple2(\"q\", 1), new Tuple2(\"z\", 1), new Tuple2(\"a\", 1));\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd = sc.parallelizePairs(data);\n",
    "    JavaPairRDD&lt;String, Integer&gt; result = rdd.sortByKey();\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('q', 1), ('z', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([(\"q\", 1), (\"z\", 1), (\"a\", 1)])\n",
    "result = rdd.sortByKey()\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.30 keys, values\n",
    "\n",
    "키와 값 쌍으로 구성된 경우에 사용할 수 있는 메서드\n",
    "\n",
    "keys() : 키에 해당하는 요소로 구성된 RDD를 생성\n",
    "    \n",
    "values() : 값에 해당하는 요소로 구성된 RDD를 리턴\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List((\"k1\", \"v1\"), (\"k2\", \"v2\"), (\"k3\", \"v3\"))\n",
    "    println(rdd.keys.collect.mkString(\",\"))\n",
    "    println(rdd.values.collect.mkString(\",\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, String&gt;&gt; data = Arrays.asList(new Tuple2(\"k1\", \"v1\"), new Tuple2(\"k2\", \"v2\"), new Tuple2(\"k3\", \"v3\"));\n",
    "    JavaPairRDD&lt;String, String&gt; rdd = sc.parallelizePairs(data);\n",
    "    System.out.println(rdd.keys().collect());\n",
    "    System.out.println(rdd.values().collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k1', 'k2', 'k3']\n",
      "['v1', 'v2', 'v3']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([(\"k1\", \"v1\"), (\"k2\", \"v2\"), (\"k3\", \"v3\")])\n",
    "print(rdd.keys().collect())\n",
    "print(rdd.values().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.31 sample\n",
    "\n",
    "샘플을 추출해 새로운 RDD를 생성.\n",
    "\n",
    "sample(withReplacement: Boolean, fraction: Double, seed: Long = Utils.random.nextLong): RDD[T]\n",
    "\n",
    "withReplacement : 복원 추출을 수행할지 여부를 정하는 것. True면 복원, False면 비복원.\n",
    "\n",
    "fraction\n",
    "\n",
    "복원 추출 : 각 요소의 평균 발생 회수. 반드시 0 이상이여야 함.\n",
    "\n",
    "비복원 추출 : 각 요소가 샘플에 포함될 확률. 0과 1 사이의 값으로 지정.\n",
    "\n",
    "seed : 반복 시행 시 결과가 바뀌지 않고 일정한 값이 나오도록 제어하는 목적.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 100)\n",
    "    val result1 = rdd.sample(false, 0.5)\n",
    "    val result2 = rdd.sample(true, 1.5)\n",
    "    println(result1.take(5).mkString(\",\"))\n",
    "    println(result2.take(5).mkString(\",\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Integer&gt; data = fillToN(100);\n",
    "    JavaRDD&lt;Integer&gt; rdd = sc.parallelize(data);\n",
    "    JavaRDD&lt;Integer&gt; result1 = rdd.sample(false, 0.5);\n",
    "    JavaRDD&lt;Integer&gt; result2 = rdd.sample(true, 1.5);\n",
    "    System.out.println(result1.take(5));\n",
    "    System.out.println(result2.take(5));\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 8, 11, 12]\n",
      "[1, 2, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize(range(1,100+1))\n",
    "result1 = rdd.sample(False, 0.5)\n",
    "result2 = rdd.sample(True, 1.5)\n",
    "print(result1.take(5))\n",
    "print(result2.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1.6 RDD 액션\n",
    "\n",
    "결과값이 정수, 리스트, 맵 등 RDD가 아닌 타입인 경우\n",
    "\n",
    "트렌스포메이션 : 결과값이 RDD인 메서드. 느긋한 평가(lazy evaluation, 지연계산) 방식을 채택.\n",
    "\n",
    "액션 메서드를 여러번 호출하면 트렌스포메이션 메서드도 여러번 실행됨."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
