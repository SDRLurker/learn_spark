{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 RDD\n",
    "\n",
    "## 2.1 RDD\n",
    "\n",
    "### 2.1.1 들어가기에 앞서\n",
    "\n",
    "#### 스파크 클러스터\n",
    "\n",
    "클러스터 : 여러 대의 서버가 마치 한 대의 서버처럼 동작하는 것\n",
    "\n",
    "스파크 클러스터 : 대량의 데이터를 여러 서버로 나누어 병렬로 처리\n",
    "\n",
    "#### RDD\n",
    "\n",
    "Resilient Distributed Dataset. 회복력을 가진 분산 데이터 집합\n",
    "\n",
    "#### RDD의 불변성\n",
    "\n",
    "RDD를 만들어 내는 방법을 기억하고 있음. 이를 통해 데이터를 다시 만들어 복구.\n",
    "\n",
    "#### 파티션\n",
    "\n",
    "데이터를 여러 서버에 나누어 저장. 스파크는 데이터를 파티션 단위로 관리.\n",
    "\n",
    "#### HDFS\n",
    "\n",
    "HDFS = 하둡 파일시스템\n",
    "\n",
    "하둡 파일시스템을 사용함으로써 나타내는 스파트 특징\n",
    "\n",
    "* 하둡의 InputFormat, OutputFormat 이용\n",
    "* 하둡과 동일하게 텍스트파일, SequenceFile, Parquet 다양한 입출력 포멧을 지원.\n",
    "* 전체 데이터를 블록(block) 단위로 분할. => 스파크에서는 파티션 단위를 원하는 값으로 조절 가능.\n",
    "\n",
    "#### Job과 Executor\n",
    "\n",
    "스파크 프로그램을 실행 = 스파크 잡(Job)을 실행. 각 서버마다 익스큐터(executor)라는 프로세스 생성.\n",
    "\n",
    "#### 드라이버 프로그램\n",
    "\n",
    "메인 함수를 가지고 있는 프로그램.\n",
    "\n",
    "스파크컨텍스트를 생성하고 그 인스턴스를 포함하고 있는 프로그램.\n",
    "\n",
    "#### 트랜스포레이션과 액션\n",
    "\n",
    "트랜스포메이션 : RDD의 형태를 변형하는 연산. 결과물로 새로운 RDD가 생성이 됨.\n",
    "\n",
    "액션 : 어떤 동작을 수행해 그 결과로 다른 타입의 결과를 반환하는 연산.\n",
    "\n",
    "#### 지연(lazy) 동작과 최적화\n",
    "\n",
    "트랜스포메이션 연산 : 해당 RDD를 사용하는 다른 액션 연산이 호출될 때까지 실제 연산을 수행하지 않는 방식으로 동작.\n",
    "\n",
    "예시) sc.textFile 실제 파일이 읽히지 않다가 saveAsTextFile 메서드를 호출하는 시점에 실제 데이터를 읽음.\n",
    "\n",
    "#### 함수의 전달\n",
    "\n",
    "함수형 프로그래밍 언어와 같이 \"함수\"를 이용한 프로그램을 작성 가능.\n",
    "\n",
    "<pre>\n",
    "var rdd1 = sc.parallelize(1 to 10) // RDD를 생성\n",
    "var rdd2 = rdd1.map(_ + 1)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "rdd1 = sc.parallelize(range(1,10+1))\n",
    "rdd2 = rdd1.map(lambda v:v+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "// 예제 2-1\n",
    "class PassingFunctionSample {\n",
    "  var count = 1\n",
    "\n",
    "  def add1(i: Int): Int = {\n",
    "    count + 1\n",
    "  }\n",
    "\n",
    "  def runMapSample(sc: SparkContext) {\n",
    "    val rdd1 = sc.parallelize(1 to 10)\n",
    "    // java.io.NotSerializableException !!!!\n",
    "    val rdd2 = rdd1.map(add)\n",
    "    println(rdd2.collect())\n",
    "  }\n",
    "}\n",
    "</pre>\n",
    "\n",
    "실행하면 java.io.NotSerializableException 에러가 발생.\n",
    "\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=nkon&logNo=150190119036\n",
    "\n",
    "map() 메서드에 전달된 함수는 클러스터를 구성하는 각 서버에서 동작할 수 있도록 클러스터에 속한 모든 워커 서버에 전달되어야 하기 때문에 Serializable 해야함.\n",
    "\n",
    "자바의 직렬화 규칙에 따라 add 함수 뿐만 아니라 PassingFunctionSample 클래스 전체가 클러스터로 전달해야 하는 대상이 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n"
     ]
    }
   ],
   "source": [
    "# 예제 2-4\n",
    "class PassingFunctionSample():\n",
    "    def add1(self, i):\n",
    "        return i + 1\n",
    "\n",
    "    def runMapSample1(self, sc):\n",
    "        rdd1 = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "        # rdd2 = rdd1.map(self.add1) # => 잘못된 방법. 'self'를 전달하고 있음.\n",
    "        rdd2 = rdd1.map(add2) # 이렇게 처리 합니다!\n",
    "        print(\", \".join(str(i) for i in rdd2.collect()))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    def add2(i):\n",
    "        return i + 1\n",
    "    \n",
    "    #conf = SparkConf()\n",
    "    #sc = SparkContext(master=\"local[*]\", appName=\"PassingFunctionSample\", conf=conf)\n",
    "\n",
    "    obj = PassingFunctionSample()\n",
    "    obj.runMapSample1(sc)\n",
    "\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인스턴스 변수를 매개변수로 전달하는 경우도 전체 클래스 인스턴스를 직렬화 하는 문제 발생.\n",
    "\n",
    "<u>메소드 내부에서 선언한 지역변수로 변환해서 전달</u> 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 타입에 따른 RDD 연산\n",
    "\n",
    "reduceByKey : 키와 값의 형태로 구성돼 있는 경우에만 이 연산을 사용할 수 있음.\n",
    "\n",
    "스파크에서는 원소가 2개짜리인 튜플 타입을 이용해 이를 표현."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 스파크컨텍스트 생성\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "val conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"RDDCreateSample\")\n",
    "val sc = new SparkContext(conf)\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "SparkConf conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"RDDCreateSample\");\n",
    "JavaSparkContext sc = new JavaSparkContext(conf);\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(master=\"local\", appName=\"RDDCreateTest\", conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 RDD 생성\n",
    "\n",
    "첫 번째 방법 : 드라이버 프로그램의 컬렉션 객체를 이용\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\", \"d\", \"e\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\"));\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD 파티션 개수를 지정하고 싶을 때에는 parallelize 2번째 매개변수를 사용\n",
    "<pre>\n",
    "val rdd1= sc.parallelize(1 to 1000, 10)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 방법 : 파일이나 데이터베이스 같은 외부 데이터를 읽어 새로운 RDD를 생성하는 방법\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "val rdd1 = sc.textFile(\"<spark_home_dir>/README.md\")\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "JavaRDD&lt;String&gt; rdd1 = sc.textFile(\"<spark_home_dir>/README.md\");\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "import os\n",
    "#rdd1 = sc.textFile(\"<spark_home_dir>/README.md\")\n",
    "rdd1 = sc.textFile(\"%s/README.md\" % os.getenv(\"SPARK_HOME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일의 각 줄은 한개의 RDD 요소(element)가 됨.\n",
    "\n",
    "파일 읽는 과정은 하둡의 TextInputFormat을 이용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 RDD 기본 액션\n",
    "\n",
    "#### 2.1.4.1 collect\n",
    "\n",
    "RDD의 모든 원소를 모아서 배열로 돌려줌. 전체 데이터를 모두 담을 수 있을 정도로 충분한 메모리 공간 확보 필요.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 10)\n",
    "    val result = rdd.collect\n",
    "    println(result.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10));\n",
    "    List&lt;Integer&gt; result = rdd.collect();\n",
    "    for (Integer i : result)\n",
    "      System.out.println(i);\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize(range(1, 10+1))\n",
    "result = rdd.collect()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4.2 count\n",
    "\n",
    "count는 RDD를 구성하는 전체 요소의 개수를 반환\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 10)\n",
    "    val result = rdd.count\n",
    "    println(result)\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10));\n",
    "    long result = rdd.count();\n",
    "    System.out.println(result);\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize(range(1, 10+1))\n",
    "result = rdd.count()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 RDD 트랜스포메이션\n",
    "\n",
    "기존 RDD를 이용해 새로운 RDD를 생성하는 연산.\n",
    "\n",
    "* 맵(map) 연산 : 요소 간의 사상(mapping)을 정의한 함수를 RDD에 속하는 모든 요소에 적용해 새로운 RDD 생성\n",
    "* 그룹화 연산 : 특정 조건에 따라 요소를 그룹화\n",
    "* 집합 연산 : 서로 다른 RDD 간에 합집합, 교집합 등을 계산\n",
    "* 파티션 연산 : RDD의 파티션 개수를 조정\n",
    "* 필터와 정렬 연산 : 특정 조건을 만족하는 요소만 선택. 각 요소를 정해진 기준에 따라 정렬."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.1 map\n",
    "\n",
    "하나의 입력을 받아 하나의 값을 돌려주는 함수를 인자(argument)로 받음.\n",
    "\n",
    "map() : 이 함수를 RDD에 속하는 모든 요소에 적용한 뒤 그 결과로 구성된 새로운 RDD를 생성해 돌려줌.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 5)\n",
    "    val result = rdd.map(_ + 1)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5));\n",
    "\n",
    "    // Java7\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = rdd1.map(new Function&lt;Integer, Integer&gt;() {\n",
    "      @Override\n",
    "      public Integer call(Integer v1) throws Exception {\n",
    "        return v1 + 1;\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaRDD&lt;Integer&gt; rdd3 = rdd1.map((Integer v1) -> v1 + 1);\n",
    "\n",
    "    System.out.println(StringUtils.join(rdd2.collect(), \", \"));\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize(range(1, 5+1))\n",
    "rdd2 = rdd1.map(lambda v : v + 1)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.2 flatMap\n",
    "\n",
    "map 메서드와 비슷하지만 반환하는 값의 타입이 다름.\n",
    "\n",
    "* map 메서드: map\\[U\\](f:(T) => U): RDD\\[U\\]\n",
    "* flatMap 메서드 : flatMap\\[U\\](f:(T) => TraversableOnce\\[U\\]): RDD\\[U\\]\n",
    "\n",
    "TraversableOnce는 스칼라에서 사용하는 이터레이터(Iterator) 타입 중 하나.\n",
    "\n",
    "<pre>\n",
    "    // 단어 3개를 가진 List 생성\n",
    "    val fruits = List(\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\")\n",
    "    // RDD 생성\n",
    "    val rdd1 = sc.parallelize(fruits)\n",
    "    // RDD의 map() 메서드로 각 단어를 \",\"를 기준으로 분리\n",
    "    val rdd2 = rdd1.map(_.split(\",\"))\n",
    "    // 결과를 출력\n",
    "    println(rdd2.collect().map(_.mkString(\"{\", \", \", \"}\")).mkString(\"{\", \", \", \"}\"))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'orange'], ['grape', 'apple', 'mango'], ['blueberry', 'tomato', 'orange']]\n"
     ]
    }
   ],
   "source": [
    "fruits = [\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\"]\n",
    "rdd1 = sc.parallelize(fruits)\n",
    "rdd2 = rdd1.map(lambda v: v.split(\",\"))\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map의 정의에 따라 T가 문자열, U가 배열이므로 결과의 타입이 RDD[배열]이 된 것.\n",
    "\n",
    "각 배열 속의 포함된 요소를 모두 배열 밖으로 끄집어내는 작업을 원함. => 이 때 flatMap 사용!\n",
    "\n",
    "하나의 입력값에 대응되는 반환값이 여러개일 때 유용하게 사용가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatMap 예제\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val fruits = List(\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\")\n",
    "    val rdd1 = sc.parallelize(fruits)\n",
    "    val rdd2 = rdd1.flatMap(_.split(\",\"))\n",
    "    print(rdd2.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;String&gt; data = new ArrayList();\n",
    "    data.add(\"apple,orange\");\n",
    "    data.add(\"grape,apple,mango\");\n",
    "    data.add(\"blueberry,tomato,orange\");\n",
    "\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(data);\n",
    "\n",
    "    JavaRDD&lt;String&gt; rdd2 = rdd1.flatMap(new FlatMapFunction&lt;String, String&gt;() {\n",
    "      @Override\n",
    "      public Iterator&lt;String&gt; call(String t) throws Exception {\n",
    "        return Arrays.asList(t.split(\",\")).iterator();\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaRDD&lt;String&gt; rdd3 = rdd1.flatMap((String t) -> Arrays.asList(t.split(\",\")).iterator());\n",
    "\n",
    "    System.out.println(rdd2.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'orange', 'grape', 'apple', 'mango', 'blueberry', 'tomato', 'orange']\n"
     ]
    }
   ],
   "source": [
    "#파이썬\n",
    "rdd1 = sc.parallelize([\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\"])\n",
    "rdd2 = rdd1.flatMap(lambda s: s.split(\",\"))\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파싱 오류시 map()을 수행한 뒤 별도의 필터단계를 추가. 아니면 다음처럼 flatMap()을 사용하여 해결.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val fruits = List(\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\")\n",
    "    val rdd1 = sc.parallelize(fruits)\n",
    "    val rdd2 = rdd1.flatMap(log => {\n",
    "      if (log.contains(\"apple\")) {\n",
    "        Some(log.indexOf(\"apple\"))\n",
    "      } else {\n",
    "        None\n",
    "      }\n",
    "    })\n",
    "    println(rdd2.collect.mkString(\",\"))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,6\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"apple,orange\", \"grape,apple,mango\", \"blueberry,tomato,orange\"])\n",
    "rdd2 = rdd1.flatMap(lambda log: str(log.index(\"apple\")) if \"apple\" in log else \"\")\n",
    "print(\",\".join(rdd2.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.3 mapPatitions\n",
    "\n",
    "RDD를 파티션 단위로 처리. 인자로 전달받은 함수를 파티션 단위로 적용, 그 결과로 구성된 새로운 RDD를 생성하는 메소드.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(1 to 10, 3)\n",
    "    val rdd2 = rdd1.mapPartitions(numbers => {\n",
    "      println(\"DB연결 !!!\")\n",
    "      numbers.map {\n",
    "        number => number + 1\n",
    "      }\n",
    "    })\n",
    "    println(rdd2.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "   JavaRDD&lt;Integer&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 3);\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = rdd1.mapPartitions(new FlatMapFunction&lt;Iterator&lt;Integer&gt;, Integer&gt;() {\n",
    "      public Iterator&lt;Integer&gt; call(Iterator&lt;Integer&gt; numbers) throws Exception {\n",
    "        System.out.println(\"DB연결 !!!\");\n",
    "        List&lt;Integer&gt; result = new ArrayList<&gt;();\n",
    "        while (numbers.hasNext()) {\n",
    "          result.add(numbers.next());\n",
    "        }\n",
    "        return result.iterator();\n",
    "      }\n",
    "\n",
    "      ;\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaRDD&lt;Integer&gt; rdd3 = rdd1.mapPartitions((Iterator&lt;Integer&gt; numbers) -&gt; {\n",
    "      System.out.println(\"DB연결 !!!\");\n",
    "      List&lt;Integer&gt; result = new ArrayList<&gt;();\n",
    "      numbers.forEachRemaining(result::add);\n",
    "      return result.iterator();\n",
    "    });\n",
    "\n",
    "    System.out.println(rdd3.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "import os\n",
    "def write_file(fn, msg):\n",
    "    with open(fn,'a' if os.path.exists(fn) else 'w') as f:\n",
    "        f.write(msg)\n",
    "        \n",
    "def increase(numbers):\n",
    "    write_file('t.txt', \"DB 연결!!!\\n\")\n",
    "    return (i + 1 for i in numbers)\n",
    "    \n",
    "rdd1 = sc.parallelize(range(1,10+1), 3)\n",
    "rdd2 = rdd1.mapPartitions(increase)\n",
    "write_file('t.txt', \"%s\\n\" % rdd2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB 연결!!!\n",
      "DB 연결!!!\n",
      "DB 연결!!!\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "cat t.txt; rm t.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdd1 생성시 파티션을 3개로 주도록 설정함. (각 파티션에 대한 처리를 할 때 'DB 연결!!!'이라는 문자열을 출력하였음.)\n",
    "\n",
    "numbers는 각 요소가 담긴 iterator 이며 그 결과를 다시 iterator로 리턴해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.4 mapPatitionsWithIndex\n",
    "\n",
    "인자로 전달받은 함수를 파티션 단위로 적용, 그 결과로 구성된 새로운 RDD를 생성하는 메소드.\n",
    "\n",
    "(콜백으로) 인자로 전달되는 함수를 호출할 때 (인덱스, iterator) 정보를 함께 전달해 줌.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(1 to 10, 3)\n",
    "    val rdd2 = rdd1.mapPartitionsWithIndex((idx, numbers) => {\n",
    "      numbers.flatMap {\n",
    "        case number if idx == 1 => Option(number + 1)\n",
    "        case _ => None\n",
    "      }\n",
    "    })\n",
    "    println(rdd2.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = rdd1.mapPartitionsWithIndex(new Function2&lt;Integer, Iterator&lt;Integer&gt;, Iterator&lt;Integer&gt;&gt;() {\n",
    "      @Override\n",
    "      public Iterator&lt;Integer&gt; call(IInteger idx, Iterator&lt;Integer&gt; numbers) throws Exception {\n",
    "        List&lt;Integer&gt; result = new ArrayList<&gt;();\n",
    "        if (idx == 1) {\n",
    "          while (numbers.hasNext()) {\n",
    "            result.add(numbers.next());\n",
    "          }\n",
    "        }\n",
    "        return result.iterator();\n",
    "      }\n",
    "    }, true);\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaRDD&lt;Integer&gt; rdd3 = rdd2.mapPartitionsWithIndex((IInteger idx, Iterator&lt;Integer&gt; numbers) -&gt; {\n",
    "      List&lt;Integer&gt; result = new ArrayList&lt;&gt;();\n",
    "      if (idx == 1)\n",
    "        numbers.forEachRemaining(result::add);\n",
    "      return result.iterator();\n",
    "    }, true);\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "def increaseWithIndex(idx, numbers):\n",
    "    for i in numbers:\n",
    "        if(idx == 1):\n",
    "            yield i\n",
    "            \n",
    "rdd1 = sc.parallelize(range(1,10+1),3)\n",
    "rdd2 = rdd1.mapPartitionsWithIndex(increaseWithIndex)\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.5 mapValues\n",
    "\n",
    "\"키\"에 해당하는 부분은 그대로 두고 \"값\"에만 map() 연산을 적용한 것과 같음.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"a\", \"b\", \"c\")).map((_, 1))\n",
    "    val result = rdd.mapValues(i => i + 1)\n",
    "    println(result.collect.mkString(\"\\t\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"));\n",
    "\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd2 = rdd1.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {\n",
    "      @Override\n",
    "      public Tuple2&lt;String, Integer&gt; call(String t) throws Exception {\n",
    "        return new Tuple2(t, 1);\n",
    "      }\n",
    "    });\n",
    "\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd3 = rdd2.mapValues(new Function&lt;Integer, Integer&gt;() {\n",
    "      @Override\n",
    "      public Integer call(Integer v1) throws Exception {\n",
    "        return v1 + 1;\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd4 = rdd1.mapToPair((String t) -&gt; new Tuple2&lt;String, Integer&gt;(t, 1)).mapValues((Integer v1) -&gt; v1 + 1);\n",
    "\n",
    "    System.out.println(rdd3.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 2), ('b', 2), ('c', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "# (키, 값) 쌍으로 구성된 RDD를 생성\n",
    "rdd2 = rdd1.map(lambda v : (v, 1))\n",
    "rdd3 = rdd2.mapValues(lambda i: i + 1)\n",
    "print(rdd3.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.6 flatMapValues\n",
    "\n",
    "\"키\"에 해당하는 부분은 그대로 두고 \"값\"에만 flatMap() 연산을 적용함.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(Seq((1, \"a,b\"), (2, \"a,c\"), (1, \"d,e\")))\n",
    "    val result = rdd.flatMapValues(_.split(\",\"))\n",
    "    println(result.collect.mkString(\"\\t\"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "   List&lt;Tuple2&lt;Integer, String&gt;&gt; data = Arrays.asList(new Tuple2(1, \"a,b\"), new Tuple2(2, \"a,c\"), new Tuple2(1, \"d,e\"));\n",
    "\n",
    "    JavaPairRDD&lt;Integer, String&gt; rdd1 = sc.parallelizePairs(data);\n",
    "\n",
    "    // Java7\n",
    "    JavaPairRDD&lt;Integer, String&gt; rdd2 = rdd1.flatMapValues(new Function&lt;String, Iterable&lt;String&gt;&gt;() {\n",
    "      @Override\n",
    "      public Iterable&lt;String&gt; call(String v1) throws Exception {\n",
    "        return Arrays.asList(v1.split(\",\"));\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaPairRDD&lt;Integer, String&gt; rdd3 = rdd1.flatMapValues((String v1) -&gt; Arrays.asList(v1.split(\",\")));\n",
    "\n",
    "    System.out.println(rdd2.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (1, 'b'), (2, 'a'), (2, 'c'), (1, 'd'), (1, 'e')]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([(1, \"a,b\"), (2, \"a,c\"), (1, \"d,e\")])\n",
    "rdd2 = rdd1.flatMapValues(lambda s: s.split(\",\"))\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그룹과 관련된 연산들**\n",
    "\n",
    "#### 2.1.5.7 zip\n",
    "\n",
    "첫 번째 RDD의 n번째 요소를 키로 하고 두 번째 RDD의 n번째 요소를 값으로 하는 순서쌍을 생성.\n",
    "\n",
    "두 RDD는 같은 개수의 파티션을 가지고 있고, 각 파티션에 속하는 요소의 수는 동일하다 가정.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\"))\n",
    "    val rdd2 = sc.parallelize(List(1, 2, 3))\n",
    "    val result = rdd1.zip(rdd2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"));\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = sc.parallelize(Arrays.asList(1, 2, 3));\n",
    "    JavaPairRDD&lt;String, Integer&gt; result = rdd1.zip(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 2), ('c', 3)]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "rdd2 = sc.parallelize([1, 2, 3])\n",
    "result = rdd1.zip(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.8 zipPartitions\n",
    "\n",
    "파티션 단위로 zip() 연산을 수행하고 특정 함수를 적용해 그 결과로 새로운 RDD를 생성하는 메서드.\n",
    "\n",
    "* zipPatitions() 연산은 집합 단위로 병합을 실행하므로 파티션의 개수만 동일해도 됨.\n",
    "* 인자로 최대 4개의 RDD를 지정가능.\n",
    "* 병합에 사용할 함수를 인자로 전달받아 사용가능.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\"), 3)\n",
    "    val rdd2 = sc.parallelize(List(1, 2, 3), 3)\n",
    "    val result = rdd1.zipPartitions(rdd2) {\n",
    "      (it1, it2) =>\n",
    "        for {\n",
    "          v1 &lt;- it1;\n",
    "          v2 &lt;- it2\n",
    "        } yield v1 + v2\n",
    "    }\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"), 3);\n",
    "    JavaRDD&lt;Integer&gt; rdd2 = sc.parallelize(Arrays.asList(1, 2, 3), 3);\n",
    "\n",
    "    // Java7\n",
    "    JavaRDD&lt;String&gt; rdd3 = rdd1.zipPartitions(rdd2, new FlatMapFunction2&lt;Iterator&lt;String&gt;, Iterator&lt;Integer&gt;, String&gt;() {\n",
    "      @Override\n",
    "      public Iterator&lt;String&gt; call(Iterator&lt;String&gt; t1, Iterator&lt;Integer&gt; t2) throws Exception {\n",
    "        List&lt;String&gt; list = new ArrayList&lt;&gt;();\n",
    "        while (t1.hasNext()) {\n",
    "          while (t2.hasNext()) {\n",
    "            list.add(t1.next() + t2.next());\n",
    "          }\n",
    "        }\n",
    "        return list.iterator();\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaRDD&lt;String&gt; rdd4 = rdd1.zipPartitions(rdd2, (Iterator&lt;String&gt; t1, Iterator&lt;Integer&gt; t2) -&gt; {\n",
    "      List&lt;String&gt; list = new ArrayList&lt;&gt;();\n",
    "      t1.forEachRemaining((String s) -&gt; {\n",
    "        t2.forEachRemaining((Integer i) -&gt; list.add(s + i));\n",
    "      });\n",
    "      return list.iterator();\n",
    "    });\n",
    "\n",
    "    System.out.println(rdd3.collect());\n",
    "</pre>\n",
    "\n",
    "실행결과\n",
    "<pre>\n",
    "[(a,2), (b,2), (c,2)]\n",
    "</pre>\n",
    "\n",
    "파이썬에서는 사용할 수 없음.\n",
    "\n",
    "rdd1, rdd2 모두 3개의 파티션으로 구성.\n",
    "\n",
    "두 RDD의 파티션에서 같은 위치에 있는 것을 연결해서 새로운 결과로 구성된 새로운 RDD를 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.9 groupBy\n",
    "\n",
    "RDD의 요소를 일정한 기준에 따라 여러 개의 그룹으로 나누고 이 그룹으로 구성된 새로운 RDD를 생성.\n",
    "\n",
    "각 그룹은 키와 그 키에 속한 시퀀스로 구성.\n",
    "\n",
    "메소드로 전달하는 함수가 각 그룹의 키를 결정하는 역할을 담당.\n",
    "\n",
    "**1에서 10까지 요소로 구성된 RDD를 홀짝으로 \"even\", \"odd\"라는 그룹으로 분류하는 예제**\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(1 to 10)\n",
    "    val result = rdd.groupBy {\n",
    "      case i: Int if (i % 2 == 0) => \"even\"\n",
    "      case _ => \"odd\"\n",
    "    }\n",
    "    result.collect.foreach {\n",
    "      v => println(s\"${v._1}, [${v._2.mkString(\",\")}]\")\n",
    "    }\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10));\n",
    "\n",
    "    // Java7\n",
    "    JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; rdd2 = rdd1.groupBy(new Function&lt;Integer, String&gt;() {\n",
    "      @Override\n",
    "      public String call(Integer v1) throws Exception {\n",
    "        return (v1 % 2 == 0) ? \"even\" : \"odd\";\n",
    "      }\n",
    "    });\n",
    "\n",
    "    // Java8 Lambda\n",
    "    JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; rdd3 = rdd1.groupBy((Integer v1) -&gt; (v1 % 2 == 0) ? \"even\" : \"odd\");\n",
    "\n",
    "    System.out.println(rdd2.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even [2, 4, 6, 8, 10]\n",
      "odd [1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize(range(1, 10+1))\n",
    "rdd2 = rdd1.groupBy(lambda v: \"even\" if v % 2 == 0 else \"odd\")\n",
    "for x in rdd2.collect():\n",
    "    print(x[0], list(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.10 groupByKey\n",
    "\n",
    "이미 RDD의 구성요소가 키와 값으로 쌍으로 이루어진 경우 사용 가능한 메서드.\n",
    "\n",
    "키를 기준을 같은 키를 가진 요소들로 그룹을 만들고 이 그룹들로 구성된 새로운 RDD를 생성.\n",
    "\n",
    "키와 그 키에 속한 요소의 시퀀스로 구성됨.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(\"a\", \"b\", \"c\", \"b\", \"c\")).map((_, 1))\n",
    "    val result = rdd.groupByKey\n",
    "    result.collect.foreach {\n",
    "      v => println(s\"${v._1}, [${v._2.mkString(\",\")}]\")\n",
    "    }\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, Integer&gt;> data = Arrays.asList(new Tuple2(\"a\", 1), new Tuple2(\"b\", 1), new Tuple2(\"c\", 1), new Tuple2(\"b\", 1), new Tuple2(\"c\", 1));\n",
    "    JavaPairRDD&lt;String, Integer&gt; rdd1 = sc.parallelizePairs(data);\n",
    "    JavaPairRDD&lt;String, Iterable&lt;Integer&gt;> rdd2 = rdd1.groupByKey();\n",
    "    System.out.println(rdd2.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [1]\n",
      "b [1, 1]\n",
      "c [1, 1]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"b\", \"c\"]).map(lambda v: (v, 1))\n",
    "rdd2 = rdd1.groupByKey()\n",
    "for x in rdd2.collect():\n",
    "    print(x[0], list(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.11 cogroup\n",
    "\n",
    "RDD의 구성요소가 키와 값의 쌍으로 된 경우에만 사용할 수 있는 메서드\n",
    "\n",
    "같은 키를 갖는 값 요소를 여러 RDD에서 찾아서 키와 그 키에 속하는 요소의 시퀀스로 된 튜플을 새로운 RDD로 생성.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List((\"k1\", \"v1\"), (\"k2\", \"v2\"), (\"k1\", \"v3\")))\n",
    "    val rdd2 = sc.parallelize(List((\"k1\", \"v4\")))\n",
    "    val result = rdd1.cogroup(rdd2)\n",
    "    result.collect.foreach {\n",
    "      case (k, (v_1, v_2)) => {\n",
    "        println(s\"($k, [${v_1.mkString(\",\")}], [${v_2.mkString(\",\")}])\")\n",
    "      }\n",
    "    }\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    List&lt;Tuple2&lt;String, String&gt;&gt; data1 = Arrays.asList(new Tuple2(\"k1\", \"v1\"), new Tuple2(\"k2\", \"v2\"), new Tuple2(\"k1\", \"v3\"));\n",
    "    List&lt;Tuple2&lt;String, String&gt;&gt; data2 = Arrays.asList(new Tuple2(\"k1\", \"v4\"));\n",
    "    \n",
    "    JavaPairRDD&lt;String, String&gt; rdd1 = sc.parallelizePairs(data1);\n",
    "    JavaPairRDD&lt;String, String&gt; rdd2 = sc.parallelizePairs(data2);\n",
    "    \n",
    "    JavaPairRDD&lt;String, Tuple2&lt;Iterable&lt;String&gt;, Iterable&lt;String&gt;&gt;&gt; result = rdd1.&lt;String&gt;cogroup(rdd2);\n",
    "\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k2 ['v2'] []\n",
      "k1 ['v1', 'v3'] ['v4']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([(\"k1\", \"v1\"), (\"k2\", \"v2\"), (\"k1\", \"v3\")])\n",
    "rdd2 = sc.parallelize([(\"k1\", \"v4\")])\n",
    "result = rdd1.cogroup(rdd2)\n",
    "for x in result.collect():\n",
    "    print(x[0], list(x[1][0]), list(x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k2 [] ['v2']\n",
      "k1 ['v4'] ['v1', 'v3']\n"
     ]
    }
   ],
   "source": [
    "result = rdd2.cogroup(rdd1)\n",
    "for x in result.collect():\n",
    "    print(x[0], list(x[1][0]), list(x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdd1.cogroup(rdd2, rdd3, ...)\n",
    "\n",
    "Tuple(키, Tuple(rdd1 요소들 집합), Tuple(rdd2 요소들 집합), Tuple(rdd3 요소들 집합)\n",
    "\n",
    "rdd2.cogroup(rdd1)\n",
    "\n",
    "Tuple(키, Tuple(rdd2 요소들 집합), Tuple(rdd1 요소들 집합))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**집합과 관련된 연산들**\n",
    "\n",
    "#### 2.1.5.12 distinct\n",
    "\n",
    "중복을 제외한 요소로만 구성된 새로운 RDD를 생성하는 메서드.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd = sc.parallelize(List(1, 2, 3, 1, 2, 3, 1, 2, 3))\n",
    "    val result = rdd.distinct()\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;Integer&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3));\n",
    "    JavaRDD&lt;String&gt; rdd2 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"));\n",
    "    JavaPairRDD&lt;Integer, String&gt; result = rdd1.cartesian(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd = sc.parallelize([1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
    "result = rdd.distinct()\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.13 cartesian\n",
    "\n",
    "두 RDD 요소를 카테시안 곱을 구하고 그 결과를 요소로 하는 새로운 RDD(key, value)를 생성하는 메서드.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(1, 2, 3))\n",
    "    val rdd2 = sc.parallelize(List(\"a\", \"b\", \"c\"))\n",
    "    val result = rdd1.cartesian(rdd2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(1, 2, 3));\n",
    "    JavaRDD&lt;String&gt; rdd2 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"));\n",
    "    JavaRDD&lt;String&gt; result = rdd1.cartesian(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c'), (3, 'a'), (3, 'b'), (3, 'c')]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([1, 2, 3])\n",
    "rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "result = rdd1.cartesian(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.14 subtract\n",
    "\n",
    "두 개의 RDD가 있을 때 rdd1.substract(rdd2)는 rdd1에는 속하고, rdd2에는 속하지 않는 요소로 구성된 새로운 RDD를 생성하는 메서드.(차집합)\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\", \"d\", \"e\"))\n",
    "    val rdd2 = sc.parallelize(List(\"d\", \"e\"))\n",
    "    val result = rdd1.subtract(rdd2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\"));\n",
    "    JavaRDD&lt;String&gt; rdd2 = sc.parallelize(Arrays.asList(\"d\", \"e\"));\n",
    "    JavaRDD&lt;String&gt; result = rdd1.subtract(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'b', 'a']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "rdd2 = sc.parallelize([\"d\", \"e\"])\n",
    "result = rdd1.subtract(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.15 union\n",
    "\n",
    "두 개의 RDD가 있을 때 rdd1 또는 rdd2에 속하는 요소로 구성된 새로운 RDD를 생성하는 메서드. \n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"b\", \"c\"))\n",
    "    val rdd2 = sc.parallelize(List(\"d\", \"e\", \"f\"))\n",
    "    val result = rdd1.union(rdd2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"b\", \"c\"));\n",
    "    JavaRDD&lt;String&gt; rdd2 = sc.parallelize(Arrays.asList(\"d\", \"e\", \"f\"));\n",
    "    JavaRDD&lt;String&gt; result = rdd1.union(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "rdd2 = sc.parallelize([\"d\", \"e\", \"f\"])\n",
    "result = rdd1.union(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'd', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 : 중복해서 원소 표시됨.\n",
    "rdd1 = sc.parallelize([\"a\", \"b\", \"c\", \"d\"])\n",
    "rdd2 = sc.parallelize([\"d\", \"e\", \"f\"])\n",
    "result = rdd1.union(rdd2)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5.16 intersection\n",
    "\n",
    "두 개의 RDD가 있을 때 rdd1, rdd2에 동시에 속하는 요소로 구성된 RDD를 생성하는 메서드. (교집합)\n",
    "\n",
    "결과로 생성되는 RDD에는 중복된 원소가 존재하지 않음.\n",
    "\n",
    "스칼라\n",
    "<pre>\n",
    "    val rdd1 = sc.parallelize(List(\"a\", \"a\", \"b\", \"c\"))\n",
    "    val rdd2 = sc.parallelize(List(\"a\", \"a\", \"c\", \"c\"))\n",
    "    val result = rdd1.intersection(rdd2)\n",
    "    println(result.collect.mkString(\", \"))\n",
    "</pre>\n",
    "\n",
    "자바\n",
    "<pre>\n",
    "    JavaRDD&lt;String&gt; rdd1 = sc.parallelize(Arrays.asList(\"a\", \"a\", \"b\", \"c\"));\n",
    "    JavaRDD&lt;String&gt; rdd2 = sc.parallelize(Arrays.asList(\"a\", \"a\", \"c\", \"c\"));\n",
    "    JavaRDD&lt;String&gt; result = rdd1.intersection(rdd2);\n",
    "    System.out.println(result.collect());\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'a']\n"
     ]
    }
   ],
   "source": [
    "# 파이썬\n",
    "rdd1 = sc.parallelize([\"a\", \"a\", \"b\", \"c\"])\n",
    "rdd2 = sc.parallelize([\"a\", \"a\", \"c\", \"c\"])\n",
    "result = rdd1.intersection(rdd2)\n",
    "print(result.collect())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
