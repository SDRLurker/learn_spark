{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 클러스터 환경\n",
    "\n",
    "## 3.1 클러스터 환경\n",
    "\n",
    "클러스터 모드 : 여러 대의 서버에서 동작하는 방식.\n",
    "\n",
    "클러스터 환경에서는 여러 서버를 마치 하나의 서버인 것처럼 다루어야 함. 분산 작업 관리 기능이 추가됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 클러스터 모드와 컴포넌트\n",
    "\n",
    "클러스터 매니저 : 전체 서버의 자원과 동작을 세밀하고 효율적으로 제어할 수 있는 모듈.\n",
    "\n",
    "잡(Job) : 전체 작업 중에 포함된 세부 작업을 가리키는 용도.\n",
    "\n",
    "드라이버 : 스파크 컨텍스트를 생성하고 관리하는 프로그램.\n",
    "\n",
    "각 워커 노드에는 익스큐터라는 스파크 프로세스가 구동되면서 작업을 수행.\n",
    "\n",
    "<img src=\"cluster-overview.png\">\n",
    "\n",
    "호스트,서버 : 주로 물리적인 장비로서의 의미.\n",
    "\n",
    "노드 : 프로그래밍 모델 관점에서 작업이 수행되는 끝점.\n",
    "\n",
    "마스터, OO매니저 : 클러스터 운영 및 제어에 사용되는 서버\n",
    "\n",
    "슬레이브, 워커, 작업노드 등 : 실제 작업에 사용되는 서버.\n",
    "\n",
    "스파크 컨텍스트 : 스파크 클러스와의 연결.\n",
    "\n",
    "모든 스파크 애플리케이션은 스파크컨텍스트를 생성으로부터 시작. \n",
    "\n",
    "1개 이상 스파크컨텍스트를 생성하거나 다른 애플리케이션이 생성한 스파크컨텍스트를 공유할 수 없음.\n",
    "\n",
    "잡은 액션 연산수 만큼 생성. 잡은 스테이지라는 단계로 나누어 실행. (셔플을 기준으로 나눔)\n",
    "\n",
    "익스큐터 역할 : 할당받은 태스크 처리. 재사용을 위해 데이터를 메모리에 저장. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 클러스터 모드를 위한 시스템 구성\n",
    "\n",
    "1. 개발서버에서 애플리케이션 코드를 작성. 테스트 수행\n",
    "2. 배포에 필요한 압축파일(jar/war, zip, egg)을 만듬\n",
    "3. 실행서버에 배포하고 작업 실행. spark-submit 스크립트 혹은 스파크 셸 스크립트를 통해 수행.\n",
    "\n",
    "배치서버/클라이언트 서버 : 클러스터에 작업을 요청하는 서버.\n",
    "\n",
    "[PC] = 1. 배포 => 배치 서버/클라이언트 서버 = 2. 작업제출 실행 / 3. 결과 취합/처리 => 스파크 클러스터\n",
    "\n",
    "**기본준비 사항**\n",
    "\n",
    "* 네트워크 설정 \n",
    " - 모든 서버들이 ssh, rsync로 파일 교환이 가능하도록 설정.\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/ssh.sh\n",
    "* JAVA_HOME 설정\n",
    "* HADOOP_HOME 설정\n",
    " - 하둡 바이너리 설치\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/hadoop.sh\n",
    "* 하둡 파일시스템(HDFS)\n",
    " - 데이터의 입력 및 출력을 위한 파일시스템으로 HDFS 사용. (아래는 hdfs 멀티노드용 설정)\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/hd_multi.sh\n",
    " \n",
    "**하둡 파일시스템 실습 예제**\n",
    "\n",
    "* 하둡 파일시스템 새로운 디렉터리 생성\n",
    "\n",
    "```shell\n",
    "$ hdfs dfs -mkdir hdfs://master:9000/sample\n",
    "```\n",
    "\n",
    "* $SPARK_HOME/README.md를 방금 생성한 디렉터리로 업로드\n",
    "\n",
    "```shell\n",
    "$ cd ${SPARK_HOME}\n",
    "$ hdfs dfs -put ./README.md hdfs://master:9000/sample\n",
    "```\n",
    "\n",
    "* ls 명령으로 파일이 잘 업로드 되었는지 확인\n",
    "\n",
    "```shell\n",
    "$ hdfs dfs -ls hdfs://master:9000/sample\n",
    "Found 1 items\n",
    "-rw-r--r--   3 spark supergroup       3809 2017-10-29 02:40 hdfs://master:9000/sample/README.md\n",
    "```\n",
    "\n",
    "**로컬 개발서버**\n",
    "\n",
    "* 스파크 셸을 이용 (일반적인 방법)\n",
    "* 메인 함수를 가진 애플리케이션을 직접 실행\n",
    "* 메인 함수를 가진 애플리케이션을 spark-submit 스크립트를 이용해 실행\n",
    "\n",
    "**애플리케이션 실행 서버**\n",
    "\n",
    "spark-submit, spark-shell 등의 스크립트를 이용해 스파크 애플리케이션을 맨처음 실행하는 서버.\n",
    "\n",
    "#### 클러스터 서버\n",
    "\n",
    "운영을 위한 마스터 서버\n",
    "\n",
    "실제 데이터를 처리하고 필요에 따라 저장하는 워커 노드의 역할을 수행하는 서버."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1.3 드라이버 프로그램과 디플로이 모드\n",
    "\n",
    "드라이버 프로그램 : 스파크 컨텍스트를 생성하는 코드가 포함된 프로그램\n",
    "\n",
    "클러스터에서 실행할 때는 클러스터 매니저에게 애플리케이션 실행을 요청하는 방식을 사용.\n",
    "\n",
    "**디플로이 모드**\n",
    "\n",
    "클라이언트 디플로이 모드 : 애플리케이션을 실행한 프로세스 내부에서 드라이버 프로그램을 구동. \n",
    "\n",
    "* 드라이버 프로그램(SparkContext) ⊆ 애플리케이션\n",
    "\n",
    "클러스터 디플로이 모드 : 클러스터 매니저에게 작업 실행만 요청. 실제 드라이버 프로그램의 실행은 클러스터 내부에서 실행.\n",
    "\n",
    "* 클러스터 매니저 <=> 드라이버 프로그램(SparkContext) ⊆ 노드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 클러스터 매니저\n",
    "\n",
    "클러스터 매니저 : 클러스터 환경에서 다수의 애플리케이션이 함께 구동될 수 있게 애플리케이션 간의 CPU나 메모리, 디스크와 같은 컴퓨팅 자원을 관리.\n",
    "\n",
    "* 하둡의 얀(Yarn)\n",
    "* 아파치의 메소스(Mesos)\n",
    "* 스탠드얼론(Standalone) : 스파크에서 자체적으로 제공."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 스탠드얼론 클러스터 매니저\n",
    "\n",
    "#### 3.2.1.1 개요\n",
    "\n",
    "**마스터 인스턴스**\n",
    "\n",
    "* 클러스터 매니저 컴포넌트.\n",
    "* 클라이언트의 요청을 받아 필요한 서버 자원을 할당.\n",
    "\n",
    "**슬레이브 인스턴스**\n",
    "\n",
    "* 워커 노드에 해당.\n",
    "* 익스큐터(Executor)와 태스크(Task)를 실행해 데이터에 대한 실제 처리와 저장을 수행하는 역할."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 설치\n",
    "\n",
    "**기본준비 사항**\n",
    "\n",
    "* 서버 준비 및 기본 설정\n",
    " - master : CPU 코어 4개, 메모리 8GB\n",
    " - slave 4대 : CPU 코어 1개, 메모리 2GB\n",
    "* ssh 접속 설정.\n",
    " - 모든 서버들이 ssh, rsync로 파일 교환이 가능하도록 설정. (하둡과 동일해서 생략가능)\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/ssh.sh\n",
    "* SCALA 설치 및 SCALA_HOME 설정.\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/scala.sh\n",
    "* SPARK 설치 및 SPARK_HOME 설정\n",
    " - 스파크 바이너리 설치. 모든 서버에 설치함.\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/spark.sh\n",
    "* slave 서버 등록.\n",
    " - start-all.sh 실행스크립트를 통해 마스터와 슬레이브를 한 번에 실행할 때 사용.\n",
    " - 어떤 서버에서 슬레이브 프로세스를 시작해야하는지 알려주어야 함.\n",
    " - https://github.com/SDRLurker/learn_spark/blob/master/spark_install/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.3 클러스터 매니저 실행\n",
    "\n",
    "$SPARK_HOME/sbin 디렉터리로 이동하면 다음 스크립트가 있음.\n",
    "\n",
    "```shell\n",
    "$ cd ${SPARK_HOME}/sbin\n",
    "```\n",
    "\n",
    "**매니저 서버 개별 실행과 종료**\n",
    "\n",
    "* start-master.sh / stop-master.sh : 마스터 인스턴스 실행 / 종료\n",
    "* start-slave.sh <마스터_url> : 슬레이브 인스턴스 실행. 예시) \n",
    " - ./start-slave.sh master:7077\n",
    "* stop-slave.sh : 슬레이브 인스턴스 종료.\n",
    "\n",
    "앞에서 정의한 slaves 파일의 내용은 아무런 영향이 없음.\n",
    "\n",
    "**한 번의 실행으로 다수의 프로세스를 구동시키고 종료**\n",
    "\n",
    "* start-slaves.sh / stop-slaves.sh : conf/slaves 파일에 등록된 서버에 슬레이브 인스턴스를 실행 / 종료\n",
    "* start-all.sh / stop-all.sh : 마스터와 슬레이브 인스턴스(conf/slaves 참조)를 모두 실행 / 종료\n",
    "\n",
    "** start-master.sh, stop-master.sh 옵션 **\n",
    "\n",
    "* -h HOST, --host HOST : 인스턴스에 접속할 호스트명을 지정\n",
    "* -p PORT, --port PORT : 마스터, 슬레이브에 접속할 포트명 지정. 마스터의 경우 디폴트 7077\n",
    "* --webui-port PORT : 웹브라우저를 통해 마스터 또는 슬레이브에 접속할 때 사용할 포트 지정. 마스터 디폴트 8080, 슬레이브는 8081.\n",
    "* -c CORES, --cores CORES : 스파크 애플리케이션이 사용 가능한 최대 코어수를 지정. 슬레이브만 지정가능. 디폴트는 가용한 전체코어가 할당.\n",
    "* -m MEM, --memory MEM : 스파크 애플리케이션이 사용 가능한 메모리를 지정. 슬레이브만 지정가능. 디폴트는 최대메모리-1GB.\n",
    "\n",
    "**스파크 마스터/슬레이브 한꺼번에 실행**\n",
    "\n",
    "```shell\n",
    "[spark@master ~]$ cd $SPARK_HOME/sbin\n",
    "[spark@master sbin]$ ./start-all.sh\n",
    "```\n",
    "\n",
    "정상적으로 실행되었는지 다음처럼 http://master:8080 으로 접속하여 확인가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html><html>\n",
       "      <head>\n",
       "        <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\"/><link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/vis.min.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/webui.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/timeline-view.css\" type=\"text/css\"/><script src=\"/static/sorttable.js\"></script><script src=\"/static/jquery-1.11.1.min.js\"></script><script src=\"/static/vis.min.js\"></script><script src=\"/static/bootstrap-tooltip.js\"></script><script src=\"/static/initialize-tooltips.js\"></script><script src=\"/static/table.js\"></script><script src=\"/static/additional-metrics.js\"></script><script src=\"/static/timeline-view.js\"></script><script src=\"/static/log-view.js\"></script><script src=\"/static/webui.js\"></script><script>setUIRoot('')</script>\n",
       "        \n",
       "        <title>Spark Master at spark://master:7077</title>\n",
       "      </head>\n",
       "      <body>\n",
       "        <div class=\"container-fluid\">\n",
       "          <div class=\"row-fluid\">\n",
       "            <div class=\"span12\">\n",
       "              <h3 style=\"vertical-align: middle; display: inline-block;\">\n",
       "                <a style=\"text-decoration: none\" href=\"/\">\n",
       "                  <img src=\"/static/spark-logo-77x50px-hd.png\"/>\n",
       "                  <span class=\"version\" style=\"margin-right: 15px;\">2.2.0</span>\n",
       "                </a>\n",
       "                Spark Master at spark://master:7077\n",
       "              </h3>\n",
       "            </div>\n",
       "          </div>\n",
       "          <div class=\"row-fluid\">\n",
       "          <div class=\"span12\">\n",
       "            <ul class=\"unstyled\">\n",
       "              <li><strong>URL:</strong> spark://master:7077</li>\n",
       "              <li>\n",
       "                    <strong>REST URL:</strong> spark://master:6066\n",
       "                    <span class=\"rest-uri\"> (cluster mode)</span>\n",
       "                  </li>\n",
       "              <li><strong>Alive Workers:</strong> 4</li>\n",
       "              <li><strong>Cores in use:</strong> 16 Total,\n",
       "                16 Used</li>\n",
       "              <li><strong>Memory in use:</strong>\n",
       "                4.0 GB Total,\n",
       "                4.0 GB Used</li>\n",
       "              <li><strong>Applications:</strong>\n",
       "                1 <a href=\"#running-app\">Running</a>,\n",
       "                2 <a href=\"#completed-app\">Completed</a> </li>\n",
       "              <li><strong>Drivers:</strong>\n",
       "                0 Running,\n",
       "                0 Completed </li>\n",
       "              <li><strong>Status:</strong> ALIVE</li>\n",
       "            </ul>\n",
       "          </div>\n",
       "        </div><div class=\"row-fluid\">\n",
       "          <div class=\"span12\">\n",
       "            <h4> Workers </h4>\n",
       "            <table class=\"table table-bordered table-condensed table-striped sortable\">\n",
       "      <thead><th width=\"\" class=\"\">Worker Id</th><th width=\"\" class=\"\">Address</th><th width=\"\" class=\"\">State</th><th width=\"\" class=\"\">Cores</th><th width=\"\" class=\"\">Memory</th></thead>\n",
       "      <tbody>\n",
       "        <tr>\n",
       "      <td>\n",
       "        <a href=\"http://10.33.1.184:8081\">\n",
       "              worker-20171029001610-10.33.1.184-38916\n",
       "            </a>\n",
       "      </td>\n",
       "      <td>10.33.1.184:38916</td>\n",
       "      <td>ALIVE</td>\n",
       "      <td>4 (4 Used)</td>\n",
       "      <td sorttable_customkey=\"1024.1024\">\n",
       "        1024.0 MB\n",
       "        (1024.0 MB Used)\n",
       "      </td>\n",
       "    </tr><tr>\n",
       "      <td>\n",
       "        <a href=\"http://10.33.3.59:8081\">\n",
       "              worker-20171029001610-10.33.3.59-36832\n",
       "            </a>\n",
       "      </td>\n",
       "      <td>10.33.3.59:36832</td>\n",
       "      <td>ALIVE</td>\n",
       "      <td>4 (4 Used)</td>\n",
       "      <td sorttable_customkey=\"1024.1024\">\n",
       "        1024.0 MB\n",
       "        (1024.0 MB Used)\n",
       "      </td>\n",
       "    </tr><tr>\n",
       "      <td>\n",
       "        <a href=\"http://10.33.5.42:8081\">\n",
       "              worker-20171029001610-10.33.5.42-41177\n",
       "            </a>\n",
       "      </td>\n",
       "      <td>10.33.5.42:41177</td>\n",
       "      <td>ALIVE</td>\n",
       "      <td>4 (4 Used)</td>\n",
       "      <td sorttable_customkey=\"1024.1024\">\n",
       "        1024.0 MB\n",
       "        (1024.0 MB Used)\n",
       "      </td>\n",
       "    </tr><tr>\n",
       "      <td>\n",
       "        <a href=\"http://10.33.8.249:8081\">\n",
       "              worker-20171029001610-10.33.8.249-44718\n",
       "            </a>\n",
       "      </td>\n",
       "      <td>10.33.8.249:44718</td>\n",
       "      <td>ALIVE</td>\n",
       "      <td>4 (4 Used)</td>\n",
       "      <td sorttable_customkey=\"1024.1024\">\n",
       "        1024.0 MB\n",
       "        (1024.0 MB Used)\n",
       "      </td>\n",
       "    </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "          </div>\n",
       "        </div><div class=\"row-fluid\">\n",
       "          <div class=\"span12\">\n",
       "            <h4 id=\"running-app\"> Running Applications </h4>\n",
       "            <table class=\"table table-bordered table-condensed table-striped sortable\">\n",
       "      <thead><th width=\"\" class=\"\">Application ID</th><th width=\"\" class=\"\">Name</th><th width=\"\" class=\"\">Cores</th><th width=\"\" class=\"\">Memory per Executor</th><th width=\"\" class=\"\">Submitted Time</th><th width=\"\" class=\"\">User</th><th width=\"\" class=\"\">State</th><th width=\"\" class=\"\">Duration</th></thead>\n",
       "      <tbody>\n",
       "        <tr>\n",
       "      <td>\n",
       "        <a href=\"app?appId=app-20171029114018-0002\">app-20171029114018-0002</a>\n",
       "        <form action=\"app/kill/\" method=\"POST\" style=\"display:inline\">\n",
       "        <input type=\"hidden\" name=\"id\" value=\"app-20171029114018-0002\"/>\n",
       "        <input type=\"hidden\" name=\"terminate\" value=\"true\"/>\n",
       "        <a href=\"#\" onclick=\"if (window.confirm('Are you sure you want to kill application app-20171029114018-0002 ?')) { this.parentNode.submit(); return true; } else { return false; }\" class=\"kill-link\">(kill)</a>\n",
       "      </form>\n",
       "      </td>\n",
       "      <td>\n",
       "        <a href=\"http://10.34.18.136:4040\">Spark shell</a>\n",
       "      </td>\n",
       "      <td>\n",
       "        16\n",
       "      </td>\n",
       "      <td sorttable_customkey=\"1024\">\n",
       "        1024.0 MB\n",
       "      </td>\n",
       "      <td>2017/10/29 11:40:18</td>\n",
       "      <td>spark</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>2.7 min</td>\n",
       "    </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "          </div>\n",
       "        </div><div>\n",
       "          \n",
       "        </div><div class=\"row-fluid\">\n",
       "          <div class=\"span12\">\n",
       "            <h4 id=\"completed-app\"> Completed Applications </h4>\n",
       "            <table class=\"table table-bordered table-condensed table-striped sortable\">\n",
       "      <thead><th width=\"\" class=\"\">Application ID</th><th width=\"\" class=\"\">Name</th><th width=\"\" class=\"\">Cores</th><th width=\"\" class=\"\">Memory per Executor</th><th width=\"\" class=\"\">Submitted Time</th><th width=\"\" class=\"\">User</th><th width=\"\" class=\"\">State</th><th width=\"\" class=\"\">Duration</th></thead>\n",
       "      <tbody>\n",
       "        <tr>\n",
       "      <td>\n",
       "        <a href=\"app?appId=app-20171029112214-0001\">app-20171029112214-0001</a>\n",
       "        \n",
       "      </td>\n",
       "      <td>\n",
       "        Spark shell\n",
       "      </td>\n",
       "      <td>\n",
       "        16\n",
       "      </td>\n",
       "      <td sorttable_customkey=\"1024\">\n",
       "        1024.0 MB\n",
       "      </td>\n",
       "      <td>2017/10/29 11:22:14</td>\n",
       "      <td>spark</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>17 min</td>\n",
       "    </tr><tr>\n",
       "      <td>\n",
       "        <a href=\"app?appId=app-20171029031422-0000\">app-20171029031422-0000</a>\n",
       "        \n",
       "      </td>\n",
       "      <td>\n",
       "        com.wikibooks.spark.ch3.scala.WordCount\n",
       "      </td>\n",
       "      <td>\n",
       "        16\n",
       "      </td>\n",
       "      <td sorttable_customkey=\"1024\">\n",
       "        1024.0 MB\n",
       "      </td>\n",
       "      <td>2017/10/29 03:14:22</td>\n",
       "      <td>spark</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>12 s</td>\n",
       "    </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "          </div>\n",
       "        </div><div>\n",
       "          \n",
       "        </div>\n",
       "        </div>\n",
       "      </body>\n",
       "    </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"http://master:8080\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* URL: spark://master:7077\n",
    " - 마스터 서버의 접속주소\n",
    "* Alive Workers: 4\n",
    " - 클러스터의 워커노드 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.4 애플리케이션 실행서버 준비\n",
    "\n",
    "여기서는 master 서버를 애플리케이션 실행서버로 사용.\n",
    "\n",
    "책은 svr-client 서버로 애플리케이션 실행서버로 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.5 애플리케이션 실행\n",
    "\n",
    "##### 3.2.1.5.1 스파크 셸\n",
    "\n",
    "--master 옵션으로 클러스터 마스터 URL 지정.\n",
    "\n",
    "```shell\n",
    "[spark@master ~]$ $SPARK_HOME/bin/spark-shell --master spark://master:7077\n",
    "```\n",
    "\n",
    "정상적으로 수행되면 'Running Applications'에 새로운 애플리케이션이 등록이 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"span12\">\n",
       "<h4 id=\"running-app\"> Running Applications </h4>\n",
       "<table class=\"table table-bordered table-condensed table-striped sortable\">\n",
       "<thead><th class=\"\" width=\"\">Application ID</th><th class=\"\" width=\"\">Name</th><th class=\"\" width=\"\">Cores</th><th class=\"\" width=\"\">Memory per Executor</th><th class=\"\" width=\"\">Submitted Time</th><th class=\"\" width=\"\">User</th><th class=\"\" width=\"\">State</th><th class=\"\" width=\"\">Duration</th></thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"app?appId=app-20171029114018-0002\">app-20171029114018-0002</a>\n",
       "<form action=\"app/kill/\" method=\"POST\" style=\"display:inline\">\n",
       "<input name=\"id\" type=\"hidden\" value=\"app-20171029114018-0002\"/>\n",
       "<input name=\"terminate\" type=\"hidden\" value=\"true\"/>\n",
       "<a class=\"kill-link\" href=\"#\" onclick=\"if (window.confirm('Are you sure you want to kill application app-20171029114018-0002 ?')) { this.parentNode.submit(); return true; } else { return false; }\">(kill)</a>\n",
       "</form>\n",
       "</td>\n",
       "<td>\n",
       "<a href=\"http://10.34.18.136:4040\">Spark shell</a>\n",
       "</td>\n",
       "<td>\n",
       "        16\n",
       "      </td>\n",
       "<td sorttable_customkey=\"1024\">\n",
       "        1024.0 MB\n",
       "      </td>\n",
       "<td>2017/10/29 11:40:18</td>\n",
       "<td>spark</td>\n",
       "<td>RUNNING</td>\n",
       "<td>2.7 min</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get(\"http://master:8080\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "HTML(str(soup.find(\"h4\", {\"id\":\"running-app\"}).parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵션을 지정하지 않을 경우 메모리는 기본 1Gb, 워커 노드는 최대 가능한 코어수로 할당.\n",
    "\n",
    "hdfs의 README.md 단어 수를 세는 예제.\n",
    "\n",
    "```scala\n",
    "scala> val inputPath = \"hdfs://master:9000/sample/README.md\"\n",
    "scala> val outputPath = \"hdfs://master:9000/sample/output\"\n",
    "scala> sc.textFile(inputPath) flatMap { line => line.split(\" \") map (word => (word, 1L)) } reduceByKey (_ + _) saveAsTextFile (outputPath)\n",
    "```\n",
    "\n",
    "결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(package,1)\n",
      "(this,1)\n",
      "(Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1)\n",
      "(Because,1)\n",
      "(Python,2)\n",
      "(page](http://spark.apache.org/documentation.html).,1)\n",
      "(cluster.,1)\n",
      "([run,1)\n",
      "(its,1)\n",
      "(YARN,,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat hdfs://master:9000/sample/output/p* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.5.2 pyspark\n",
    "\n",
    "--master 옵션으로 클러스터 마스터 URL 지정.\n",
    "\n",
    "```shell\n",
    "[spark@master ~]$ $SPARK_HOME/bin/pyspark --master spark://master:7077\n",
    "```\n",
    "\n",
    "정상적으로 수행되면 'Running Applications'에 새로운 애플리케이션이 등록이 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"span12\">\n",
       "<h4 id=\"running-app\"> Running Applications </h4>\n",
       "<table class=\"table table-bordered table-condensed table-striped sortable\">\n",
       "<thead><th class=\"\" width=\"\">Application ID</th><th class=\"\" width=\"\">Name</th><th class=\"\" width=\"\">Cores</th><th class=\"\" width=\"\">Memory per Executor</th><th class=\"\" width=\"\">Submitted Time</th><th class=\"\" width=\"\">User</th><th class=\"\" width=\"\">State</th><th class=\"\" width=\"\">Duration</th></thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"app?appId=app-20171029114649-0003\">app-20171029114649-0003</a>\n",
       "<form action=\"app/kill/\" method=\"POST\" style=\"display:inline\">\n",
       "<input name=\"id\" type=\"hidden\" value=\"app-20171029114649-0003\"/>\n",
       "<input name=\"terminate\" type=\"hidden\" value=\"true\"/>\n",
       "<a class=\"kill-link\" href=\"#\" onclick=\"if (window.confirm('Are you sure you want to kill application app-20171029114649-0003 ?')) { this.parentNode.submit(); return true; } else { return false; }\">(kill)</a>\n",
       "</form>\n",
       "</td>\n",
       "<td>\n",
       "<a href=\"http://10.34.18.136:4040\">PySparkShell</a>\n",
       "</td>\n",
       "<td>\n",
       "        16\n",
       "      </td>\n",
       "<td sorttable_customkey=\"1024\">\n",
       "        1024.0 MB\n",
       "      </td>\n",
       "<td>2017/10/29 11:46:49</td>\n",
       "<td>spark</td>\n",
       "<td>RUNNING</td>\n",
       "<td>31 s</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\"http://master:8080\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "HTML(str(soup.find(\"h4\", {\"id\":\"running-app\"}).parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정상적으로 수행되면 'Running Applications'에 \"PySparkShell\"이 구동중인 것을 확인가능.\n",
    "\n",
    "hdfs의 README.md 단어 수를 세는 예제.\n",
    "\n",
    "```python\n",
    ">>> inputPath = \"hdfs://master:9000/sample/README.md\"\n",
    ">>> outputPath = \"hdfs://master:9000/sample/output\"\n",
    ">>> result = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word:(word,1L)).reduceByKey(lambda v1, v2: v1+v2)\n",
    ">>> result.saveAsTextFile(outputPath)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'', 71L)\n",
      "(u'storage', 1L)\n",
      "(u'\"local\"', 1L)\n",
      "(u'including', 4L)\n",
      "(u'computation', 1L)\n",
      "(u'file', 1L)\n",
      "(u'Maven', 1L)\n",
      "(u'using:', 1L)\n",
      "(u'guidance', 2L)\n",
      "(u'Scala,', 1L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat hdfs://master:9000/sample/output/p* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.5.3 spark-submit을 이용한 애플리케이션 실행\n",
    "\n",
    "배포 파일을 만들고 이를 스파크 클러스터에 디플로이해서 실행하는 것이 더 편리함.\n",
    "\n",
    "일관된 방법으로 애플리케이션을 실행가능하며 실행 매개변수를 이용해 각각 다르게 설정 가능.\n",
    "\n",
    "애플리케이션 코드를 작성한 뒤 jar 파일을 생성. (파이썬의 경우 .py나 zip, egg)\n",
    "\n",
    "스칼라로 작성한 단어 수 세기 예제\n",
    "\n",
    "```scala\n",
    "package com.wikibooks.spark.ch3.scala\n",
    "\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.rdd.RDD.rddToPairRDDFunctions\n",
    "\n",
    "object WordCount {\n",
    "\n",
    "  def run(inputPath: String, outputPath: String) {\n",
    "    val conf = new SparkConf()\n",
    "    val sc = new SparkContext(conf)\n",
    "\n",
    "    sc.textFile(inputPath)\n",
    "      .flatMap(_.split(\" \"))\n",
    "      .map((_, 1L))\n",
    "      .reduceByKey(_ + _)\n",
    "      .saveAsTextFile(outputPath)\n",
    "\n",
    "    sc.stop()\n",
    "  }\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    val numberOfArgs = 2\n",
    "    if (args.length == numberOfArgs) {\n",
    "      run(args(0), args(1))\n",
    "    } else {\n",
    "      println(\"Usage: $SPARK_HOME/bin/spark-submit --class <class_name> --master <master> --<option> <option_value> <jar_file_path> <input_path> <output_path>\")\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "메이븐으로 jar 배포용 파일을 생성\n",
    "```shell\n",
    "[spark@master ~]$ git clone https://github.com/wikibook/spark.git\n",
    "[spark@master ~]$ cd spark\n",
    "[spark@master spark]$ mvn -Dmaven.test.skip=true clean package\n",
    "```\n",
    "\n",
    "~/sparkApps 디렉터리 생성 및 jar 파일을 복사\n",
    "```shell\n",
    "[spark@master spark]$ mkdir -p ~/sparkApps\n",
    "[spark@master spark]$ cp -p ../deploy/beginning-spark-examples.jar ~/sparkApps\n",
    "```\n",
    "\n",
    "하둡파일 시스템에 이전 출력 파일 삭제\n",
    "```shell\n",
    "[spark@master spark]$ hdfs dfs -rm -r hdfs://master:9000/sample/output\n",
    "```\n",
    "\n",
    "스파크 애플리케이션을 실행\n",
    "```shell\n",
    "[spark@master spark]$ cd $SPARK_HOME\n",
    "[spark@master spark]$ ./bin/spark-submit --class com.wikibooks.spark.ch3.scala.WordCount --master spark://master:7077 ~/sparkApps/beginning-spark-examples.jar hdfs://master:9000/sample/README.md hdfs://master:9000/sample/output\n",
    "```\n",
    "\n",
    "결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(package,1)\n",
      "(this,1)\n",
      "(Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1)\n",
      "(Because,1)\n",
      "(Python,2)\n",
      "(page](http://spark.apache.org/documentation.html).,1)\n",
      "(cluster.,1)\n",
      "([run,1)\n",
      "(its,1)\n",
      "(YARN,,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat hdfs://master:9000/sample/output/p* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 작성한 단어 수 세기 예제\n",
    "\n",
    "```python\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import sys\n",
    "\n",
    "class WordCount:    \n",
    "    def run(self, inputPath, outputPath):\n",
    "        conf = SparkConf()        \n",
    "        sc = SparkContext(conf=conf)\n",
    "        sc.textFile(inputPath).flatMap(lambda s : s.split(\" \")).map(lambda s: (s, 1)).reduceByKey(lambda v1, v2:v1 + v2).saveAsTextFile(outputPath)\n",
    "        sc.stop()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    app = WordCount()\n",
    "    \n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: $SPARK_HOME/bin/spark-submit --master <master> --<option> <option_value> <python_file_path> <input_path> <output_path>\")\n",
    "    else:\n",
    "        app.run(sys.argv[1], sys.argv[2])\n",
    "```\n",
    "\n",
    "실행방법\n",
    "```shell\n",
    "[spark@master ~]$ spark-submit --master spark://master:7077 $HOME/spark/Python/ch3/wordcount.py hdfs://master:9000/README.md hdfs://master:9000/output\n",
    "```\n",
    "\n",
    "결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'', 71)\n",
      "(u'when', 1)\n",
      "(u'R,', 1)\n",
      "(u'including', 4)\n",
      "(u'computation', 1)\n",
      "(u'contributing', 1)\n",
      "(u'using:', 1)\n",
      "(u'guidance', 2)\n",
      "(u'Scala,', 1)\n",
      "(u'environment', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat hdfs://master:9000/sample/output/p* | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.2.1.6 디플로이 모드\n",
    "\n",
    "--deploy-mode 옵션을 사용해 \"cluster\"와 \"client\" 모드 중 하나를 지정 가능.\n",
    "\n",
    "기본값은 \"client\" 모드.\n",
    "\n",
    "배포 jar 파일을 slave에 복사.(책에 없음)\n",
    "```shell\n",
    "[spark@master ~]$ scp -rp sparkApps/ slave01:~/.\n",
    "[spark@master ~]$ scp -rp sparkApps/ slave02:~/.\n",
    "[spark@master ~]$ scp -rp sparkApps/ slave03:~/.\n",
    "[spark@master ~]$ scp -rp sparkApps/ slave04:~/.\n",
    "```\n",
    "\n",
    "스파크 애플리케이션을 \"cluster\" 모드에서 실행\n",
    "```shell\n",
    "\n",
    "[spark@master ~]$ cd $SPARK_HOME\n",
    "[spark@master spark]$ ./bin/spark-submit --class com.wikibooks.spark.ch3.scala.WordCount --master spark://master:7077 --deploy-mode cluster ~/sparkApps/beginning-spark-examples.jar hdfs://master:9000/sample/README.md hdfs://master:9000/sample/output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.7 주요 설정\n",
    "\n",
    "conf의 spark-env.sh 파일을 만들고 \"export 변수=값\" 형태로 환경변수를 저장.\n",
    "\n",
    "자세한 내용은 https://goo.gl/hrxard 참조\n",
    "\n",
    "**마스터 및 슬레이브 실행 스크립트의 명령행 매개변수**\n",
    "\n",
    "* --properties-file : 스파크 설정 파일의 위치를 지정. 기본으로는 spark-defaults.conf 파일 사용.\n",
    "\n",
    "**주요 환경변수(모든 스크립트에 적용)**\n",
    "\n",
    "* SPARK_WORKER_MEMORY : 스파크 애플리케이션이 사용 가능한 메모리를 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
